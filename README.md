# llvm-llm-profile-driven-iterative-optimization

「–O3 後の LLVM IR を LLM が動的プロファイル情報を取り込みつつ反復的に最適化し、最終バイナリをビルド・デバッグまで自動化する」システム

---

## システム構成

1. **VSCode タスク群 (`.vscode/tasks.json`)**  
   - 1 → 5 のステップを自動実行するビルドタスクを定義  
     1. `clang -O3` で IR 出力  
     2. `perf stat` によるベンチマーク実行＆プロファイル取得  
     3. プロファイル結果を自然言語に整形  
     4. LLM 呼び出しスクリプトで IR 最適化（プロファイル統合＋反復ループ）  
     5. 最適化済 IR からバイナリを生成  

2. **プロファイル整形スクリプト (`profile_and_parse.py`)**  
   - `perf stat` の出力（cycles, instructions, cache-misses など）をパース  
   - 「プログラムの実行プロファイル」としてマークダウン形式に変換  

3. **LLM 最適化スクリプト (`optimize_ir_llm.py`)**  
   - 入力：元の IR テキスト ＋ プロファイルテキスト  
   - プロンプトに「–O3 以上に最適化してください。特にホットスポットに注目して…」と指示  
   - `--iterations` 回だけ（例：3 サイクル）呼び出し→逐次 IR を更新  
   - 最終的に最適化 IR をファイル出力  

4. **ビルド＆デバッグ設定 (`.vscode/launch.json`)**  
   - 最終バイナリのステップ実行やブレークポイントによる動作検証を VSCode 内で完結  

この一連を “`Ctrl+Shift+B`” の一発操作で動かせるのが最大の特徴

---

## 新規性

1. **反復フィードバックループの自動化**  
   - ただ一度 LLM を呼ぶのではなく、性能評価→結果フィードバック→再最適化を複数サイクルで自動実行  
   - サイクルごとの性能推移を定量的に取得でき、LLM の最適化収束特性を初めて可視化・分析可能

2. **動的プロファイル統合**  
   - 静的 IR だけでなく、実行時のホットスポット情報（perf 統計）をプロンプトに組み込み  
   - 「実行プロファイル×プログラム構造」のクロスモーダル最適化を LLM に学習させることで、従来の静的最適化手法や単一プロンプト最適化を上回るポテンシャルを実現

3. **VSCode とのシームレス統合**  
   - 開発者が馴染み深い IDE 上で、最適化フロー全体をワンクリック自動化  
   - 学術実験環境としてだけでなく、エンジニアの実開発ワークフローにも自然に組み込める汎用性を兼備


<img width="190" alt="image" src="https://github.com/user-attachments/assets/0e859c14-fef4-4adf-b499-564b46d5f58a" />
