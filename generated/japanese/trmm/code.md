<details><summary>c</summary>


* `A`：M×M、**下三角**, `Aᵗ`（転置）使用
* `B`：M×N（一般行列）

---

##  **ベース：`trmm.c`**

```c
for (i)
  for (j)
    for (k = i+1; k < M; k++)
      B[i][j] += A[k][i] * B[k][j];
    B[i][j] *= alpha;
```

*  PolyBench `#pragma scop` に準拠
*  `B[i][j]` はループ内で `+=` → メモリ更新2回（読み書き2回）
*  `alpha` は毎要素掛け（ベクトル化不十分）

---

##  `opt_1.c` の違い【`sum`導入 + 式再構成】

```c
DATA_TYPE sum = B[i][j];
for (k = i+1; ...)
  sum += A[k][i] * B[k][j];
B[i][j] = alpha * sum;
```

*  `B[i][j]` を一時変数 `sum` で保持 → メモリアクセス削減
*  `alpha` 掛け算を `sum` にまとめることで**1回のみ**
*  PolyBench `#pragma scop` 対応

>  **opt\_1** = 式展開により **読み書き最小化 + メモリ参照数削減**

---

##  `opt_2.c` の違い【`sum` + 更新後の `+=` 構造】

```c
sum = B[i][j];
for (k = i+1; ...)
  sum += A[k][i] * B[k][j];
B[i][j] *= alpha;
B[i][j] += alpha * sum;
```

*  `B[i][j]` に2回アクセス（`*=`, `+=`）
*  `alpha * sum` が `+=` に分離
*  2重書き込み（`B[i][j]`）のため、**再利用性は低め**

>  **opt\_2** = `sum`導入はするが、**メモリ書き込み最小化には未達**

---

##  `opt_3.c` の違い【命令順序変更 + 強化構造】

```c
B[i][j] *= alpha;
for (k = i+1; ...)
  B[i][j] += alpha * A[k][i] * B[k][j];
```

*  すべて `B[i][j]` に直接反映（`sum` 使わず）
*  `alpha` を毎回掛けてはいるが、**再代入式で命令数抑制**
*  `alpha * A[k][i] * B[k][j]` は毎回再計算

>  **opt\_3** = **ループ内乗算共通化を捨てて直列更新を選択**（命令圧縮寄り）

---

##  比較表

| 特徴                       | `trmm.c` | `opt_1.c`  | `opt_2.c`     | `opt_3.c`      |
| ------------------------ | -------- | ---------- | ------------- | -------------- |
| PolyBench `#pragma scop` | ✅        | ✅          | ❌             | ❌              |
| メモリアクセス最小化               | ❌（2回）    | ✅（`sum`経由） | ❌（2回）         | ⚠️ 直接更新（共通化なし） |
| `alpha` の適用方法            | 毎回掛ける    | 最後に一括      | 2回（`*=`と`+=`) | 毎回掛けるが融合       |
| 再利用性（計算 vs メモリ）          | ❌        | ✅          | ⚠️ 一部         | ⚠️ 演算再利用無し     |

---

##  結論

* **opt\_1.c**：最もバランスの良い構造（計算・メモリ最適化両立）
* **opt\_2.c**：命令分離によりコード明瞭性重視、ただし性能低下あり
* **opt\_3.c**：命令圧縮狙いの再代入構造 → SIMDに適する可能性あり

---
</details>

<details><summary>ll</summary>


---

##  **base.ll（ベース構造）**

*  `__kmpc_*` 系関数なし → OpenMP 無し
*  `vectorize.*` メタ無し → LLVM自動ベクトル化対象外
*  SIMD命令（`<N x float>`）出現なし
*  三重ループ構造（`i, j, k`）で `B[i][j] += A[k][i] * B[k][j]` を直接更新
*  `B[i][j]` に2回アクセス（読み + 書き）

---

##  `opt_1.ll` の違い【`sum` によるメモリアクセス削減】

*  `sum = B[i][j]` → `%sum = load`
*  `sum += A[k][i] * B[k][j]` → `%sum = fadd`
*  最後に `B[i][j] = alpha * sum` → `fmul` + `store`
*  `B[i][j]` は **1回の write に抑制**（パフォーマンス向上）
*  SIMD命令なし、OpenMPも無し
*  `fmul` → `fadd` のシンプルな命令構造で **SIMD誘導に適する**

>  **opt\_1.ll** = 命令再構成により **ロード回数を最小化した最適IR**

---

##  `opt_2.ll` の違い【二重更新構造】

*  `sum` 初期化後、`B[i][j] *= alpha` → 1回目 `store`
*  `B[i][j] += alpha * sum` → 再度 `load` + `store`
*  メモリアクセス 2回（`store` が2つ）
*  ベクトル化メタ・SIMD命令ともに無し
*  命令数は多少抑えているが、**書き込み競合リスクあり**

>  **opt\_2.ll** = 明示的命令分割により、**可読性重視のIR設計**

---

##  `opt_3.ll` の違い【命令融合再代入構造】

*  `B[i][j] *= alpha` → `fmul` + `store`
*  ループ中 `B[i][j] += alpha * A[k][i] * B[k][j]`

  * `%tmp1 = load B[i][j]`
  * `%tmp2 = fmul alpha * A[k][i]`
  * `%tmp3 = fmul tmp2 * B[k][j]`
  * `%sum = fadd tmp1 + tmp3`
  * `store %sum → B[i][j]`
*  毎回 `load + fadd + store` が発生 → 書き込み最適性なし
*  SIMD命令・vectorメタなし

>  **opt\_3.ll** = 計算構造を直列的に融合した**低依存高実行可能性型**

---

##  LLVM IR 比較表

| 特徴                             | base.ll | opt\_1.ll  | opt\_2.ll | opt\_3.ll   |
| ------------------------------ | ------- | ---------- | --------- | ----------- |
| OpenMP 並列 (`__kmpc_*`)         | ❌       | ❌          | ❌         | ❌           |
| SIMD命令（`<4 x float>` 等）        | ❌       | ❌          | ❌         | ❌           |
| `vectorize` メタデータ              | ❌       | ❌          | ❌         | ❌           |
| `B[i][j]` の `load`/`store` 最適化 | ❌       | ✅（1回）      | ❌（2回）     | ❌（毎ループ書き込み） |
| 式展開 / 命令整理                     | ❌       | ✅（`sum`活用） | ✅（2回に分離）  | ✅（逐次命令化）    |

---

##  結論

* **opt\_1.ll**：`sum`活用で最小限のアクセスに抑えた **最も効率的なIR構造**
* **opt\_2.ll**：分かりやすさ重視 → **書き込み回数が増える点がネック**
* **opt\_3.ll**：命令を融合してループ化 → **パイプライン実行には強いが再利用性低い**

---

</details>
