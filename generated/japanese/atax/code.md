<details><summary>c</summary>

---

##  **ベースライン: `atax.c`**

基本的な処理の流れは次の通り：

1. **初期化**: `y[i] = 0`
2. **第1段階**: `tmp[i] = Σ A[i][j] * x[j]`
3. **第2段階**: `y[j] += A[i][j] * tmp[i]`

ループ順序:

```c
for i in M:
  for j in N:
    tmp[i] += ...
  for j in N:
    y[j] += ...
```

 並列化・ベクトル化なし
 全体を `#pragma scop` で囲み、PolyBench最適化前提で整備されている。

---

## ⚙️ `opt_1.c` の違い【フュージョン型】

*  `atax.c` と同様のループ構造、ただし `tmp[i]` の計算後に `y[j] += A[i][j] * tmp[i]` を**同一ループ内に統合**
*  `memset(y, 0, ...)` を使用して初期化
*  並列化なし
*  全体スコープも `#pragma scop` で囲まれている

>  `opt_1` = **ループフュージョン**でメモリ参照の局所性強化。性能の向上を狙うが、スレッド対応はまだ。

---

## ⚙️ `opt_2.c` の違い【逐次分離 + 再構成】

*  `y` の初期化を `memset` に変更（高速化）
*  `tmp` の計算ループと `y` の更新ループを明示的に分割
*  各ループ内で `sum` 変数を導入し、一時的に保持 → **レジスタ利用の最適化を誘発**
*  OpenMP 並列化なし

>  `opt_2` = `opt_1` の融合とは逆に**分離構造**でキャッシュ効率とレジスタ最適化を意図。

---

##  `opt_3.c` の違い【フル並列化】

*  `#pragma omp parallel for` を3か所に適用：

  1. `y[j] = 0` 初期化
  2. `tmp[i] = Σ A[i][j] * x[j]`
  3. `y[j] += Σ A[i][j] * tmp[i]`
*  `reduction(+:y[:n])` による**配列部分の和の競合回避**
*  `tmp` と `y` の再利用性を考慮した**最終形の並列設計**

>  `opt_3` = OpenMP フル活用 + 配列リダクションの導入 → **マルチスレッド環境で最大の並列性能**

---

##  最適化比較表

| 特徴                      | `atax.c` | `opt_1`        | `opt_2`  | `opt_3`        |
| ----------------------- | -------- | -------------- | -------- | -------------- |
| `y`初期化方法                | ループ      | `memset`       | `memset` | OpenMP ループ     |
| `tmp` と `y` の計算順        | 分離       | **統合（fusion）** | 分離（再構成）  | 分離 + 並列        |
| OpenMP 並列化              | ❌        | ❌              | ❌        | ✅ 全段階          |
| `reduction(+:y[:n])` 使用 | ❌        | ❌              | ❌        | ✅（競合回避）        |
| 最適化意図                   | 素直な      | データ局所性         | レジスタ利用誘導 | 並列性とスケーラビリティ重視 |

---

##  結論

* **opt\_1**：ループフュージョンでキャッシュ効率化。
* **opt\_2**：分離 + `sum`変数でレジスタ最適狙い。
* **opt\_3**：完全並列 + OpenMP リダクションでマルチスレッド実行に最適化。

---
  
</details>

<details><summary>ll</summary>

---

##  **ベースライン（base.ll）特徴**

*  OpenMP 呼び出しなし：`__kmpc_*` 関数存在せず
*  ループに `!llvm.loop.vectorize`, `!llvm.loop.unroll` などの最適化メタデータなし
*  `memset` の代わりにループで `y[i] = 0` 実装
* 処理順：`tmp[i] = A[i][j]*x[j]`, `y[j] += A[i][j]*tmp[i]` の**2段階計算**

---

##  `opt_1.ll` の違い

*  **ループ構造の融合**：IR上でも `store`/`load` のタイミングが近接（`tmp[i]`計算と同じループ内で `y[j] +=` 実行）
*  OpenMP 呼び出しなし
*  ベクトル命令（`<N x double>`）未使用
*  ループメタデータなし

>  `opt_1.ll` = 単一スレッドかつベクトル化無しだが、\*\*ループ統合（fusion）\*\*によるメモリ参照の最適化が反映されたIR。

---

##  `opt_2.ll` の違い

* `memset` 展開が `llvm.memset.*` 形式で明示されている
*  ループ分離：IR上で `tmp[i]` 用ループと `y[j]` 用ループが**明確に独立**
*  一時変数 `sum` が `%sum = fadd ...` の形で複数命令に出現（レジスタ保持）
*  並列化なし
*  メタデータなし（アンローリング・ベクトル化）

>  `opt_2.ll` = メモリ書き込みの再配置と計算式の一時変数化により、**レジスタ効率を意識した中間表現**。

---

##  `opt_3.ll` の違い

*  OpenMP ランタイム関数の出現（`__kmpc_fork_call`, `__kmpc_for_static_init`）
*  並列処理部分が `@.omp_outlined.*` に分離され、IR上で outline関数化
*  `y[:] += ...` の計算が `reduction(+:y)` 相当の記述で展開（メモリ競合対応）
*  ループ中に `load <4 x double>` など SIMD命令が存在（環境依存）
*  `!llvm.loop.vectorize.enable = true` 等のメタデータが付加される場合あり

>  `opt_3.ll` = 並列化・SIMD化・IR内アウトライン構造を含む**フルスケール最適化版**。

---

##  差分比較まとめ表

| 特徴項目         | base.ll | opt\_1.ll    | opt\_2.ll     | opt\_3.ll                    |
| ------------ | ------- | ------------ | ------------- | ---------------------------- |
| OpenMP 並列化   | ❌       | ❌            | ❌             | ✅ `__kmpc_*` ランタイム           |
| ループ構造        | 2段階分離   | 融合           | 明示的分離         | 分離 + 並列                      |
| ベクトル命令（SIMD） | ❌       | ❌            | ❌             | ✅ `<N x double>` など          |
| ループ最適化メタデータ  | ❌       | ❌            | ❌             | ✅ `!llvm.loop.vectorize.*` 等 |
| メモリ初期化最適化    | ループ     | `memset`（なし） | `llvm.memset` | `llvm.memset` + 並列化          |
| 配列リダクション競合回避 | ❌       | ❌            | ❌             | ✅ `reduction`構文 + atomic操作?  |

---

##  総括

* **`opt_1.ll`** = メモリ参照統合の IR 構造反映。**CPUキャッシュ最適**
* **`opt_2.ll`** = 一時変数保持の明確化により、**コンパイラによる命令選択を誘導**
* **`opt_3.ll`** = 並列処理・ベクトル処理・構造分離すべてを実現。**IR最適化の完成形**

---

</details>
