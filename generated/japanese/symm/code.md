<details><summary>c</summary>

---

##  `symm.c`（ベース）

```c
for (i)
  for (j)
    temp2 = 0;
    for (k < i) {
      C[k][j] += alpha * B[i][j] * A[i][k];
      temp2   += B[k][j] * A[i][k];
    }
    C[i][j] = beta * C[i][j] + alpha * B[i][j] * A[i][i] + alpha * temp2;
```

*  ループ不変式の計算最適化なし
*  `A[i][k]` や `B[i][j]` を複数回読み出し
*  並列化なし
*  `#pragma scop` 対応（PolyBench解析可能）

---

##  `opt_1.c` の違い【ループ内共通項の抽出】

*  `alpha_Bij = alpha * B[i][j]` を前計算
*  `A[i][k]` を変数化 → `C[k][j] += alpha_Bij * A[i][k]`
*  `temp2 += B[k][j] * A[i][k]`
*  `alpha * A[i][i]` を前もって `alpha_Aii` にして適用

```c
DATA_TYPE alpha_Bij = alpha * B[i][j];
...
C[k][j] += alpha_Bij * A[i][k];
```

>  **opt\_1** = 式展開と共通部分の変数化による**命令数削減**

---

##  `opt_2.c` の違い【ループ不変最適化 + 計算構造整理】

*  `alpha_Bij` と `alpha_Aii` 両方変数化（`A[i][i]` も事前計算）
*  `B[k][j]` はそのまま → メモリアクセスは改善無し
*  式全体を `C[i][j] = sum1 + alpha_Bij * A[i][i] + alpha * temp2;` に整理

```c
sum1 = beta * C[i][j];
...
C[i][j] = sum1 + alpha_Bij * A[i][i] + alpha * temp2;
```

>  **opt\_2** = 不変式の抽出と再構成で**再利用性と命令数削減**を両立

---

##  `opt_3.c` の違い【最適再利用 + アクセス数最小化】

*  `B[i][j]`, `A[i][i]` は一度だけ読み込み → `alpha_Bij`, `alpha_Aii` としてキャッシュ
*  `A[i][k]`, `B[k][j]` の読み込みはループ内変数化 → メモリアクセス回数削減
*  式を完全に分離構造にして再利用性を最大化

```c
DATA_TYPE Aik = A[i][k];
DATA_TYPE Bkj = B[k][j];
C[k][j] += alpha_Bij * Aik;
temp2 += Bkj * Aik;
```

>  **opt\_3** = **最小メモリアクセス + 最大計算再利用** → 完全に構造最適化済み

---

##  比較表

| 特徴                          | `symm.c`（ベース） | `opt_1.c`      | `opt_2.c` | `opt_3.c` |
| --------------------------- | ------------- | -------------- | --------- | --------- |
| `alpha * B[i][j]` 事前計算      | ❌             | ✅              | ✅         | ✅         |
| `A[i][i]` 事前計算              | ❌             | ✅（`alpha_Aii`） | ✅         | ✅         |
| `A[i][k]`, `B[k][j]` の変数化   | ❌             | ❌（`A[i][k]`のみ） | ❌         | ✅（両方）     |
| 式の構造再整理                     | ❌             | ⚠️ 部分的         | ✅ 全体を明示   | ✅ 最小命令で明示 |
| メモリアクセス削減                   | ❌             | ⚠️ 部分改善        | ❌         | ✅（再利用最適化） |
| PolyBench `#pragma scop` 対応 | ✅             | ✅              | ✅         | ✅         |

---

##  結論

* **opt\_1**：共通式を分離し**演算回数を削減**
* **opt\_2**：不変式をより適切に構造化し、**計算順序を整理**
* **opt\_3**：再利用率・キャッシュ効率・命令密度の観点で**最高性能構造**

---

</details>

<details><summary>ll</summary>

---

##  **base.ll（非最適化）特徴**

*  `__kmpc_*` 系呼び出しなし → OpenMP 並列化なし
*  `!llvm.loop.vectorize.enable` 無し → LLVM SIMD命令生成対象外
*  SIMD命令（`<N x float>`）出現なし
*  三重ループ構成：`i-j-k`
* メモリアクセスが冗長（`A[i][k]`, `B[k][j]`, `B[i][j]` の多重アクセス）

---

##  `opt_1.ll` の違い【一部式展開による命令数削減】

*  `alpha_Bij` の事前計算：IR内で `fmul` → `%alpha`, `%B_ij` の組み合わせ
*  `A[i][k]` は毎回 load
*  SIMD命令なし
*  `vectorize` メタなし
*  `%C_kj` 加算が `fadd` 1回に集約

>  **opt\_1.ll** = スカラー計算での**共通式展開**が見られるが、メモリアクセス最適化は不十分

---

##  `opt_2.ll` の違い【演算式再構成 + 一部依存排除】

*  `alpha_Bij` + `alpha_Aii` の事前計算あり（IRで明示 `fmul`×2）
*  `sum1 = beta * C[i][j]` 明示 → 加算ルートを一元化
*  SIMD命令なし
*  `!llvm.loop.vectorize.enable` メタなし
*  `A[i][k]`, `B[k][j]` は繰り返し load

>  **opt\_2.ll** = **中間演算を分離**しつつ、IR内の演算構造を再整理した**中間構造**

---

##  `opt_3.ll` の違い【IR最適構造 + 演算・アクセス再利用最大化】

*  `A[i][k]`, `B[k][j]` は `%Aik`, `%Bkj` として明示 load → メモリ参照回数削減
*  `%alpha_Bij` + `%alpha_Aii` を事前算出し reuse
*  `%temp2` はループ内でベクトルリダクションしやすい構造
*  IRにおける計算ステップが再利用性最大に近い形へ展開されている
*  SIMD命令はまだ出現していないが **SIMDフレンドリー構造**

>  **opt\_3.ll** = LLVM IR上で**最もキャッシュ・再利用最適化された構造**

---

##  LLVM IR 差分まとめ

| 特徴                            | base.ll | opt\_1.ll      | opt\_2.ll | opt\_3.ll            |
| ----------------------------- | ------- | -------------- | --------- | -------------------- |
| OpenMP 並列化（`__kmpc_*`）        | ❌       | ❌              | ❌         | ❌                    |
| ベクトル化メタ（`vectorize.*`）        | ❌       | ❌              | ❌         | ❌                    |
| SIMD命令（`<4 x float>` 等）       | ❌       | ❌              | ❌         | ❌                    |
| `alpha * B[i][j]` の事前計算       | ❌       | ✅ `%alpha_Bij` | ✅         | ✅                    |
| `A[i][k]`, `B[k][j]` のload数削減 | ❌       | ❌              | ❌         | ✅ `%Aik`, `%Bkj` 明示  |
| 命令再利用/演算効率最適化                 | ❌       | ⚠️ 一部式展開あり     | ✅（構造再整理）  | ✅（再利用 + 依存最小 + 変数最適） |

---

##  結論

* **opt\_1.ll**：式展開により演算数は少し減るが、アクセスパターン未改善
* **opt\_2.ll**：式の順序や構造を改善して**再利用性を確保**
* **opt\_3.ll**：**メモリアクセス数最小 + LLVM最適構造誘導**に対応した最適IR

---

</details>
