<details><summary>c</summary>

---

##  **ベース：`trisolv.c`**

```c
for (i)
  x[i] = b[i];
  for (j < i)
    x[i] -= L[i][j] * x[j];
  x[i] /= L[i][i];
```

*  `#pragma scop` による PolyBench 対象スコープ定義
*  OpenMP 無し（逐次実行）
*  ベクトル化 / 演算共通化無し
*  `x[i]` は更新しながら使われるため **逐次依存性あり**

---

##  `opt_1.c` の違い【OpenMP 並列（逐次依存無視）】

```c
#pragma omp parallel for private(j)
```

*  `i` ループに対する OpenMP 並列導入
*  `x[i] = ... - L[i][j]*x[j]` → **データ依存あり**（x\[j]使用前に書き込みが未保証）
*  スレッドセーフではない（**計算順が結果に影響する可能性**）

>  **opt\_1** = 並列化試行版だが、**逐次依存に無頓着な危険構造**

---

##  `opt_2.c` の違い【OpenMP + SIMD】

```c
#pragma omp parallel for
  ...
  #pragma omp simd reduction(-:sum)
  for (j < i)
    sum -= L[i][j] * x[j];
```

*  `sum` に対する SIMD 演算適用（リダクション）
*  `x[j]` はループ外で既に確定してるため、**read-only参照**として SIMD 適用可能
*  `sum = b[i];` → `x[i] = sum / L[i][i];` → 明確なデータ分離

>  **opt\_2** = **SIMDリダクションでループ高速化**、ただしスレッド並列の安全性は`x[]`依存に注意

---

##  `opt_3.c` の違い【OpenMP + 逐次依存分離】

```c
#pragma omp parallel for private(j)
for (i)
  sum = b[i];
  for (j < i)
    sum -= L[i][j] * x[j];
  x[i] = sum / L[i][i];
```

*  `sum` の導入により `x[i]` 更新はループ外
*  OpenMP 並列化あり（ただしデータ依存性解決はされていない）
*  `x[i]` 書き込みは他スレッドの `x[j]` 読み込みに影響 → **並列実行は不正確な可能性あり**

>  **opt\_3** = 書き込み対象と read-only を分離したが、**逐次依存の根本的回避なし**

---

##  比較表

| 特徴                       | `trisolv.c` | `opt_1.c` | `opt_2.c`            | `opt_3.c`      |
| ------------------------ | ----------- | --------- | -------------------- | -------------- |
| PolyBench `#pragma scop` | ✅           | ❌         | ❌                    | ❌              |
| OpenMP 並列                | ❌           | ✅（不完全）    | ✅                    | ✅（依存あり）        |
| SIMD リダクション              | ❌           | ❌         | ✅ `#pragma omp simd` | ❌              |
| データ依存（`x[i]` → `x[j]`）   | ✅（逐次）       | ❌（不整合）    | ⚠️ read-only で部分的に回避 | ❌（書き込み競合リスクあり） |

---

##  結論

* **opt\_1.c**：並列導入したが **逐次依存性を無視** → **不正確な結果のリスク**
* **opt\_2.c**：**SIMD化** により内ループの加速成功 → 正当性も保持されやすい
* **opt\_3.c**：`x[i]` 書き込みを分離したが、並列実行には **依存性の壁** が残る

---

</details>

<details><summary>ll</summary>

---

##  **base.ll（逐次処理構造）**

*  `__kmpc_*` 呼び出しなし → OpenMP 無し
*  `!llvm.loop.vectorize` メタ無し → ベクトル化非対応
*  SIMD命令（`<N x float>`）無し
*  ネストループ：スカラー演算で `x[i]` を順に更新（依存あり）

---

##  `opt_1.ll` の違い【OpenMP並列導入（危険構造）】

*  `__kmpc_fork_call`, `__kmpc_for_static_init` 出現 → OpenMP あり
*  `x[i]` を書き込みつつ `x[j]` を読み込む構造維持 → **逐次依存性未解決**
*  SIMD命令出現なし
*  `omp reduction` 無し

>  **opt\_1.ll** = 並列構造導入したが、**データ依存性解決が無く競合の可能性あり**

---

##  `opt_2.ll` の違い【OpenMP + SIMDリダクション構造】

*  OpenMP + `omp.simd` 対応 → `sum` への `fadd` が `reduction(+:sum)` 相当
*  `%sum` 初期化 + ループ中に `fadd` → `store x[i] = sum / L[i][i]` の構造
*  `x[j]` 読み出しに対する依存性解析はあるが、`i` ループの並列化は非推奨（順次依存性）
*  `__kmpc_fork_call` 出現ありでも、**逐次実行を前提にした安全なSIMD化**

>  **opt\_2.ll** = **ループ内リダクションはベクトル化可能**、ただし並列性には依存注意

---

##  `opt_3.ll` の違い【構造再整理＋OpenMP並列】

*  `sum = b[i] - Σ(L[i][j]*x[j])` → `x[i] = sum / L[i][i]` 分離構造あり
*  OpenMP並列 (`__kmpc_*`) 出現 → `i` 並列を試みている
*  データ依存は解決されていない：`x[j]` 読み出しは他スレッドが更新しているかも
*  SIMD命令無し、`vectorize` メタも無し

>  **opt\_3.ll** = 構造的に最適化されたように見えるが、**逐次依存回避には至らず**

---

##  比較表（LLVM IR）

| 特徴                         | base.ll | opt\_1.ll | opt\_2.ll         | opt\_3.ll  |
| -------------------------- | ------- | --------- | ----------------- | ---------- |
| OpenMP 並列 (`__kmpc_*`)     | ❌       | ✅（不正確）    | ✅（限定的）            | ✅（逐次依存未処理） |
| SIMD命令（`<N x float>`）      | ❌       | ❌         | ⚠️ 部分リダクション対応     | ❌          |
| `omp simd reduction` 相当の構造 | ❌       | ❌         | ✅ `%sum` に `fadd` | ❌          |
| データ依存の解消                   | ❌       | ❌         | ✅（ループ内のみ）         | ❌          |
| `x[i] = ...` 構造の分離         | ✅       | ✅         | ✅                 | ✅          |

---

##  結論

* **opt\_1.ll**：OpenMP導入されるも、**逐次依存を無視したため危険**
* **opt\_2.ll**：SIMD可能なリダクション構造で、内ループの高速化に成功
* **opt\_3.ll**：構造最適化されたが、OpenMP並列化と依存性の整合性は取れていない

---
</details>
