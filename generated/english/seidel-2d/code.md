<details><summary>c</summary>

---

##  **コードベース：`seidel-2d_opt_3.c` の最適化内容**

###  **並列化**（OpenMP）

* `kernel_seidel_2d()` 内で `#pragma omp parallel` を使用し、時間ステップ内ループ (`i`) をスレッドで分割。
* 各スレッドが `i` 行単位で独立に処理可能 ⇒ **並列化の恩恵大**。

```c
#pragma omp parallel
{
  ...
  #pragma omp for schedule(static) nowait
  for (i = 1; i < n - 1; i++) {
    ...
  }
}
```

---

##  **LLVM IR 比較（base.ll / opt\_1.ll / opt\_2.ll / opt\_3.ll）**

| 項目                          | base.ll | opt\_1.ll               | opt\_2.ll                 | opt\_3.ll                             |
| --------------------------- | ------- | ----------------------- | ------------------------- | ------------------------------------- |
| OpenMPパラレル化                 | ❌       | ❌                       | ❌                         | ✅ `omp.outlined`使用                    |
| ループスケジューリングメタ (`llvm.loop`) | ❌       | ✅ `unroll.enable=false` | ✅ `vectorize.enable=true` | ✅ `unroll`, `vectorize` 両方            |
| 関数分離 (関数アウトライン)             | ❌       | ❌                       | ❌                         | ✅ `@.omp_outlined` 生成                 |
| SIMD命令                      | ❌       | ❌                       | 一部                        | ✅ `llvm.loop.vectorize.enable = true` |

---

## opt\_3 最適化の意図と利点

###  **目的**

* 計算コア部分（9点平均）をマルチスレッドで高速化
* SIMDを効かせることでキャッシュヒット率向上と並列演算効率化

###  **実際の効果**

* `i` ごとにデータ依存性がないため、OpenMPで完全分割可能
* `prev` 変数を使った再利用によりレジスタ効率向上
* `new_val` を一時変数化し命令の再順序最適化を可能に

---

##  結論：`seidel-2d`最適化比較まとめ

| 最適化レベル | 並列化 | SIMD化 | メタデータ最適化    | 説明                         |
| ------ | --- | ----- | ----------- | -------------------------- |
| base   | ❌   | ❌     | ❌           | 素朴な逐次ループ構造                 |
| opt\_1 | ❌   | ❌     | 🔹ループメタ少し改善 | 軽度な最適化のみ                   |
| opt\_2 | ❌   | ✅     | ✅ループベクトル化ON | SIMD処理による高速化意図             |
| opt\_3 | ✅   | ✅     | ✅完全最適化      | **並列＆SIMDフル活用**。最高性能が見込まれる |

---

</details>

<details><summary>ll</summary>

---

## 「seidel-2d」ベース vs opt\_1 / opt\_2 / opt\_3の最適化比較まとめ：

###  **元コード（`seidel-2d.c`）の基本構造：**

* ループ順：`for (t) for (i) for (j)`
* 各 `A[i][j]` 更新に必要な9点の周囲セルの合計を用いて計算。
* 並列処理なし（OpenMPなし）
* 完全に逐次実行

---

###  **opt\_1.c の違い：**

* **OpenMP追加**：`#pragma omp parallel for` により `i` ループの並列化。
* **処理粒度**：ループの分割はしていないが、スレッドによる分散処理が可能。
* **スカラー計算と書き込み**の一貫性維持（依存関係を避けている）

 改善点：

* 並列化によって実行速度向上が期待される。

 限界：

* キャッシュフレンドリではない。`A[i][j]` を繰り返しアクセスしやすいとは言えない。

---

###  **opt\_2.c の違い：**

* **OpenMPの強化**：`collapse(2)` による `i` と `j` のネストループの並列化。
* **`#pragma omp simd`** を導入し、SIMDベクトル化によるループ内高速化を促進。

 改善点：

* より細かい並列単位。マルチコアでの効率が高まる。
* SIMDにより計算ループのベクトル命令化が期待される。

 注意点：

* `collapse(2)` は依存のあるループには不向きなため、慎重に適用しないと誤動作の危険あり。

---

###  **opt\_3.c の違い：【📄参照済み】**

* **OpenMP並列ブロック＋fine-grain制御**

  ```c
  #pragma omp parallel
  {
    #pragma omp for schedule(static) nowait
  ```
* **ループ中の`prev`と`new_val`の一時変数導入**で、`A[i][j]`の依存関係を緩和。
* **ベクトル化はなし**（`simd`なし）

 改善点：

* `prev` 変数によってメモリアクセスの再利用性UP（`A[i][j]` → `prev`)
* `nowait` によってスレッド間の同期コスト削減

 限界：

* SIMD最適化されていないため、ベクトルユニットは活用していない

---

##  総括：

| 最適化レベル | 並列化                    | SIMD | キャッシュ活用  | コメント          |
| ------ | ---------------------- | ---- | -------- | ------------- |
| opt\_1 | OMPあり（i）               | ❌    | △        | ベーシック並列化      |
| opt\_2 | OMP collapse(2) + SIMD | ✅    | △        | ハードウェア活用最大化志向 |
| opt\_3 | OMP並列+`prev`変数         | ❌    | ✅（書き換え少） | メモリアクセス効率重視   |

---

</details>
