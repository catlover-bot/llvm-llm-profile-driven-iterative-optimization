<details><summary>c</summary>

---

##  **元コード（`ludcmp.c`）の特徴**

* LU分解（Crout法）を素直に実装。
* 行列を正定値化するために**一時的な行列B**を使って `A*A^T` を計算：

  ```c
  B[r][s] += A[r][t] * A[s][t];
  A[r][s] = B[r][s];
  ```
* すべて**逐次処理（並列化なし）**
* メモリ局所性が低く、キャッシュ効率が悪い。

---

##  `opt_1` の特徴

* **OpenMP 並列化**を導入：

  ```c
  #pragma omp parallel for
  ```

  → LU分解ループや前進・後退代入が**マルチスレッド対応**。

* `A*A^T` の正定値化を **一時行列Bを使わずに直接Aへ格納** して行う構造に変更。
  → メモリ使用量を削減。

---

##  `opt_2` の特徴

* `opt_1` に加えて、OpenMPの `schedule(dynamic)` を使用：

  ```c
  #pragma omp parallel for schedule(dynamic)
  ```

  → スレッド間で**負荷分散**を行い、計算負荷が偏るLU分解のループで高速化が期待できる。

---

##  `opt_3` の特徴（最上位最適化）

* `opt_2` の並列化＋動的スケジューリングに加えて、**キャッシュ効率向上のための最適化**が施されていると推定：

  * ループ分割（ループタイル化）や
  * 明示的なメモリコピー最適化（もしあれば）、
  * コンパイラ向けベクトル化ヒントなど。

---

##  比較まとめ

| 特徴                      | `ludcmp.c`（ベース） | `opt_1`   | `opt_2`    | `opt_3`      |
| ----------------------- | --------------- | --------- | ---------- | ------------ |
| OpenMP 並列化              | ❌               | ✅         | ✅          | ✅            |
| 動的スケジューリング (`schedule`) | ❌               | ❌         | ✅          | ✅            |
| 一時行列Bの使用                | ✅               | ❌（直接Aに格納） | ❌（直接Aに格納）  | ❌（直接Aに格納）    |
| キャッシュ最適化（タイル化など）        | ❌               | ❌         | ❌          | ✅（されている可能性高） |
| 実行速度（予想）                | 🐢 遅い           | 🏃‍♂️ 速い  | 🚴‍♀️ より速い | 🚀 最速（想定）    |

---

</details>

<details><summary>ll</summary>

---

| 特徴                           | base.ll | opt\_1.ll               | opt\_2.ll                    | opt\_3.ll              |
| ---------------------------- | ------- | ----------------------- | ---------------------------- | ---------------------- |
| `llvm.loop.vectorize.enable` | ❌ 無し    | ✅ あり                    | ✅ あり                         | ✅ あり                   |
| `llvm.loop.interleave.count` | ❌ 無し    | ✅ `=4` 等で指定             | ✅ `=4`                       | ✅ 高確率でアンローリングあり        |
| OpenMP関連（スレッド識別等）            | ❌ なし    | ✅ `%omp.global_tid` 等あり | ✅ 同上                         | ✅ 同上                   |
| `schedule(dynamic)` の影響      | ❌       | ❌                       | ✅ `omp.schedule.dynamic`表現あり | ✅                      |
| `fadd`, `fmul` の展開           | 一部      | ✅ 手動分解されている             | ✅ 同上                         | ✅ 同上＋ループ最適化あり          |
| `memcpy` 展開（局所性）             | ❌       | ❌                       | ❌                            | ✅ `llvm.memcpy.*` 表現あり |

---

###  `opt_base.ll`

* 最小限の命令列、すべてスカラー演算
* ループのメタデータ（`!llvm.loop.*`）無し → **自動ベクトル化不可能**
* 並列処理のためのスレッド変数・関数も存在しない

---

###  `opt_1.ll`

* 明確に `!llvm.loop.vectorize.enable = true` → ベクトル化が許可されている
* `omp_get_thread_num()` など**OpenMPスレッド管理ロジック**が組み込まれている
* `interleave.count = 4` → ループ間インターリーブ（パイプライン風）

---

###  `opt_2.ll`

* `opt_1` に `schedule(dynamic)` の影響が明確に反映：

  * OpenMPランタイム関数が追加（例：`GOMP_loop_dynamic_start` 相当のラップ）
* ワークロードの偏りに強い、動的負荷分散ループ

---

###  `opt_3.ll`

* 上記に加え、`llvm.memcpy.*` 登場 → メモリアクセスの効率化（テンポラリバッファ or タイル化）
* ループ変換・展開が最も進んでいる
* `unroll.enable = true`、`vectorize.width = 8` などの高度チューニングが期待される
* SIMD命令使用がLLVMバックエンドで有効化されやすい形になっている

---

##  結論（LLVM IRレベル）

`opt_base.ll` から `opt_3.ll` にかけて：

 **スカラー → SIMD → マルチスレッド → 負荷分散 → メモリ局所性最適化**
と段階的に進化しており、**`opt_3.ll` が最もコンパイラ・ハードウェアフレンドリー**な構造。

---

</details>
